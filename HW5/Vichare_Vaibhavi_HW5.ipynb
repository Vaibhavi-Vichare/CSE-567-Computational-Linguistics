{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vichare_Vaibhavi_HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW5: Evaluating machine translated output (31 possible points)\n",
        "\n",
        "In this homework, we will be assessing the properties of a machine translation system between a language you probably do not speak (Finnish) into a language you probably do speak (English). The goal of this homework is to get you to:\n",
        "\n",
        "1. Use the huggingface `transformers` package\n",
        "2. Build a function that can evaluate the quality of a back-translation\n",
        "3. Build a function that can evaluate machine translated output using a _monolingual_ language model\n",
        "\n",
        "## The data\n",
        "\n",
        "You will be using two files for this assignment -- `en-fi-en-translations.txt` and `fi-en-fi-translations.txt`. Each line in the files is tab-separated into columns. The following schema is used for both files:\n",
        "\n",
        "1. Language 1 (e.g. `ENG`)\n",
        "2. Language 2 (e.g. `FIN`)\n",
        "3. Correct intermediate sentence (e.g., the `FIN` translation)\n",
        "4. Original sentence (i.e., Language 1's original form)\n",
        "5. Round trip translated sentence (i.e., the output of translating from ENG -> FIN -> ENG)\n",
        "\n",
        "The data was generated using two large neural machine translation (NMT) models. These models were trained on open subtitle corpora, which are largely from movies and TV shows. NMT models are usually trained on parallel text, so the subtitles (or captions) from one segment in a movie are usually assumed to line up with the same line in another movie.\n",
        "\n",
        "Most of the modern models treat machine translation as a sequence-to-sequence problem. That is, we try to find the best representation of an input sequence (e.g., a sequence of English words) to predict an output sequence (e.g., a sequence of Finnish words). There are lots of tricks to make the model work, but for this homework we are interested in seeing how easily we can faithfully represent the original input to our machine translation systems by testing **backtranslation** or a specific case of round-trip machine translation that basically goes L1-L2-L1.\n",
        "\n",
        "## The languages\n",
        "\n",
        "But, languages vary in the way they encode different types of linguistic information. For example, Finnish has much more complex morphology than English does, which means that many different strings in Finnish can translate to exactly the same string in English. You can look up various grammatical properties of Finnish in the WALS database: https://wals.info/languoid/lect/wals_code_fin\n",
        "\n",
        "Here are a handful of facts about Finnish within the Morphology domain:\n",
        "\n",
        "* Exclusively concatenative\n",
        "* Case + number\n",
        "* 2-3 categories per word\n",
        "* Dependent marking\n",
        "* Double marking in possessive noun phrases\t\n",
        "* Strongly suffixing\n",
        "\n",
        "Likewise you can find out more about English here: https://wals.info/languoid/lect/wals_code_eng\n",
        "\n",
        "Take a look at these pages before you start the full assignment -- it will help you understand the data better."
      ],
      "metadata": {
        "id": "4KJTY7iGK9t9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Create a function that loads the data (2 points)\n",
        "\n",
        "**Create a function called `load_data`** that takes a file path, opens the file, processes the file using the `.readlines()` method. Create a list called `data`. Then the function should loop through each row and split it along the `\\t` character, and append this list to `data`. Return `data` at the end of the loop. "
      ],
      "metadata": {
        "id": "YJy3K-cqfgQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cadvD4u00oSc",
        "outputId": "53de7929-ad3b-44d0-a769-48dbb6410bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer for Q1 goes here\n",
        "def load_data(filepath):\n",
        "  data = []\n",
        "  file = open(filepath, \"r\")\n",
        "  if file.mode == 'r':\n",
        "    file_contents = file.readlines()\n",
        "    #print(file_contents)\n",
        "  for line in file_contents:\n",
        "    data.append(line.split(\"\\t\"))\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "3XVOr1oVk5MR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2: Loading in data (4 points)"
      ],
      "metadata": {
        "id": "I_OFFhuZeF57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2a: Loading in the English round trip data (2 points)\n",
        "\n",
        "Load in `en-fi-en.txt` saved to a variable called `english`.\n",
        "\n",
        "You may load in the file to colab or jupyter however is most convenient for you.\n",
        "\n",
        "Print out the contents of `english`."
      ],
      "metadata": {
        "id": "jiYLkQ3RkkHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load in English data\n",
        "english = load_data(\"/content/drive/MyDrive/Computational Linguistic/HW5-3/en-fi-en-translations.txt\")"
      ],
      "metadata": {
        "id": "Km3NimGXK-W_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print contents of `english`\n",
        "for contents_english in english:\n",
        "  print (contents_english)"
      ],
      "metadata": {
        "id": "-yvPdWh6twSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2b: Loading in the Finnish round trip data (2 points)\n",
        "\n",
        "Load in `fi-en-fi.txt`, saved as a variable called `finnish`.\n",
        "\n",
        "You may load in the file to colab or jupyter however is most convenient for you.\n",
        "\n",
        "Print out the contents of `finnish`."
      ],
      "metadata": {
        "id": "Rhm7H3uth7zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load in Finnish data\n",
        "finnish = load_data(\"/content/drive/MyDrive/Computational Linguistic/HW5-3/fi-en-fi-translations.txt\") "
      ],
      "metadata": {
        "id": "6fNCPJ9ni1GE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print contents of `finnish`\n",
        "for contents_finnish in finnish:\n",
        "  print(contents_finnish)"
      ],
      "metadata": {
        "id": "loJY23pDtxjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3: Qualitative evaluation (7 points)\n",
        "\n",
        "Referring to the output of Q2a and Q2b, pick two cases that the model got right and three cases that the model got wrong, in terms of reconstructing the original message. Show us the 2 incorrect and 3 correct cases.\n",
        "\n",
        "For the Finnish translations, you may want to consider the English sentence as well. For both languages, propose 3 possible contributing _linguistic_ factors that may influence whether the backtranslations are correct/incorrect. For example, did any of the linguistic properties of English or Finnish from the WALS database appear in the examples you picked? \n",
        "\n",
        "As far as you can tell, does it look like one language was easier to translate into or out of than the other? Can you think of linguistic and non-linguistic reasons why this might be the case?"
      ],
      "metadata": {
        "id": "YWqjwxg-K9q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3a\n",
        "\n",
        "Right:\n",
        "1. \n",
        "> Gold output =  'All they had to do was stop' \\\n",
        "> Translated output = 'All they had to do was stop'\n",
        "2. \n",
        "> Gold output = 'I don't have a computer.' \\\n",
        "> Translated output = 'I don't have a computer.'\n",
        "\n",
        "Wrong:\n",
        "\n",
        "1. \n",
        "> Gold output =  'All you need to do is wait.' \\\n",
        "> Translated output = 'All you have to do is wait.'\n",
        "2. \n",
        "> Gold output = 'Be quiet!' \\\n",
        "> Translated output = 'Shut up!'\n",
        "3. \n",
        "> Gold output = 'Give us a hand. \\\n",
        "> Translated output = 'Give me a hand.'\n",
        "\n",
        "\n",
        "Qualitatively evaluate the English-English data here by answering the questions above.\n",
        "According to me, the possible contributing *linguistic* factors that influences whether backtransaltions are correct or wrong are:\n",
        ">1. Epistemic Possibility.\n",
        ">2. Morphological Imperative.\n",
        ">3. Inclusive/Exclusive Distinction in Verbal Inflection.\n",
        ">4. Present/Past Tense.\n",
        ">5. Predicative Possession \\\n",
        "\n",
        "So in 'Right' section, for the first sentence, the output of gold sentence and translated sentence is matched beause they use 'Past Tense' where it meant is 'they just needed to do one thing which was stop'. Then the second sentence is a type of 'Predicative Possession' where it is telling that particular person doesn't has a possession of a particular object.\n",
        "And in the 'Wrong' section, for the first sentence, the translated sentence is showing 'Present Tense' where as the gold sentence is showing some kind of suggesion, that's why the result is not matching.For the second sentence, the english language has no morphologically dedicated second-person imperatives at all. Because of that only the results are wrong. For the third sentence, eventhough it uses 'Inclusive/Exclusive Distinction in Verbal Inflection' meaning in English language 'We and I are same' it still showing that result is not correct.\n"
      ],
      "metadata": {
        "id": "Wbz3qICWs6xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3b\n",
        "\n",
        "Right\n",
        "1. \n",
        "> Gold output = 'Ovatko kätesi puhtaat?' \\\n",
        "> Translated output = 'Ovatko kätesi puhtaat? ' \\\n",
        "> Google Translation = 'Are your hands clean?' \\\n",
        "\n",
        "2. \n",
        "> Gold output = 'Mene kysymään Tomilta' \\\n",
        "> Translated output = 'Mene kysymään Tomilta' \\\n",
        "> Google Translation = 'Go ask Tom' \\\n",
        "\n",
        "Wrong\n",
        "\n",
        "1. \n",
        "> Gold output = Perusteellinen aseistariisuntasopimus kieltää kaikki aseistukset ja asevoimat.  \\\n",
        "> Google Translation = A thorough disarmament treaty prohibits all regulations and armed forces. \\\n",
        "> Translated output = 'Kattava aseriisuntasopimus kieltää kaiken aseistuksen ja asevoimat.'  \n",
        "> Google Translation = 'A comprehensive disarmament treaty bans all armaments and the armed forces' \\\n",
        "\n",
        "2. \n",
        "> Gold output = Hänen apunsa tuli viime tingassa.  \\\n",
        "> Google Translation = His/Her help came last time. \\\n",
        "> Translated output = Hänen apunsa tuli viime hetkellä \\\n",
        "> Google Translation = Her/His help came at the last minute \\\n",
        "\n",
        "3. \n",
        "> Gold output = Anteeksi, missä on WC?.  \\\n",
        "> Google Translation = Excuse me, where is the toilet? \\\n",
        "> Translated output = Anteeksi, missä vessa on? \\\n",
        "> Google Translation = Sorry about where the toilet is \\\n",
        "\n",
        "Qualitatively evaluate the Finnish-Finnish data here by answering the questions above.\n",
        "> The big difference between Finnish and English is that, gendered pronouns are not distinguished, as you can see in example 2 of 'Wrong' section, it kind of creates confusion whether is it he or she. But in finnish language it bascially consider as 'it'. In every sentence they only use one tense which is present tense, as the future tense is not there in finnish language. So it is difficult to understand wheather statment written over here is in present tense or future tense. Also, in finnsih language you can express your thoughts in lesser words, that's why in example 2 of 'Right' section, it uses only three words, instead of forming entire sentence."
      ],
      "metadata": {
        "id": "Bafz57yis-89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3c\n",
        "\n",
        "Discuss potential linguistic and non-linguistic reasons for errors.\n",
        "> There are various reasons in linguistic and non-linguistic area where it causes error because of that, like, \\\n",
        "-- The person wheather he is linguistic or non-linguistic if he is not familar with other native langauges, then because of that it causes errors in result. \\\n",
        "-- Sometimes if the person is working continously on some data, then he/she might get tired and because of that also it causes error. \\\n",
        "-- As the rules of languages(grammer rules) are different from one another, so while performing translation there are chances that it may leads to error. "
      ],
      "metadata": {
        "id": "ccB2bRYrKgAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4: Exact string matching (5 points)\n",
        "\n",
        "For this question, you should compute the average accuracy of each of the datasets using _strict_ exact string matching. That is, you should compare the translated output (the 4th/final column in each data entry) to the gold output (the 3rd/second-to-last column in each data entry) for both `ENG` and `FIN`.\n",
        "\n",
        "To do this, write a function called `score` that does the following:\n",
        "\n",
        "0. Create an empty list called `matches`\n",
        "1. Takes the dataset (e.g., `english` or `finnish` as an argument) and loops through every row:\n",
        "  * Identifies the gold sentence\n",
        "  * Identifies the translated sentence\n",
        "  * Compares whether (2) is exactly the same string as (3) as a boolean called `match`\n",
        "  * Appends `match` to `matches`\n",
        "2. Returns the mean of `matches` (accuracy for the full dataset)\n",
        "\n",
        "For both `ENG` and `FIN`, run `score` and print the accuracy out to the notebook."
      ],
      "metadata": {
        "id": "1nn82Q__K9nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def score(dataset):\n",
        "  matches = []\n",
        "  gold_sentence = []\n",
        "  translated_sentence = []\n",
        "  data = dataset\n",
        "  for contents in data:\n",
        "    gold_sentence.append(contents[-2].strip('\\n').split('\\n'))\n",
        "  for contents in data:\n",
        "    translated_sentence.append(contents[-1].strip('\\n').split('\\n'))\n",
        "  \n",
        "  for i in range(len(gold_sentence)):\n",
        "    if gold_sentence[i] == translated_sentence[i]:\n",
        "      match = True\n",
        "      matches.append(int(match))\n",
        "    else:\n",
        "      match = False\n",
        "      matches.append(int(match))\n",
        "  return np.mean(matches)"
      ],
      "metadata": {
        "id": "_hja5XRh7BHA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute and print accuracy for english\n",
        "accuracy_english = score(english)\n",
        "print(\"Accuracy for English\", accuracy_english)"
      ],
      "metadata": {
        "id": "XneLBcahLimI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7637a9-99a9-4fdd-d681-2464fedd7eeb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for English 0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute and print accuracy for finnish\n",
        "accuracy_finnish = score(finnish)\n",
        "print(\"Accuracy for Finnish\", accuracy_finnish)"
      ],
      "metadata": {
        "id": "o65PqmoyLicg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60bd8d5-de3c-4b5c-f858-5885351dec97"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Finnish 0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5: Monolingual embedding comparisons (10 points)\n",
        "\n",
        "In this section, we would like you to compute the similarity between the two sentences for each translation. Specifically, we will use `BERT`, a large language model, as a _sentence encoder_ that will produce one 768-dimensional vector for each token in our sentences. In the below, we use a tokenizer to transform a sentence $s$ into $k$ subwords, and then we give a pre-trained model the tokenized representation of $s$. The result is a `(1, k, 768)` dimensional tensor at each layer.\n",
        "\n",
        "The layers are held together in a `tuple`, in which the first element is the lowest layer, and the last element is the highest layer."
      ],
      "metadata": {
        "id": "aVhO6TXxK9f-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5a: Run the next cell to load in the English and Finnish BERT models (1 points)"
      ],
      "metadata": {
        "id": "Uex069kuOMh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "finbert = BertModel.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\")\n",
        "finbert.eval()\n",
        "fintokenizer = BertTokenizer.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\")\n",
        "\n",
        "engbert = BertModel.from_pretrained(\"bert-base-cased\")\n",
        "engbert.eval()\n",
        "engtokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "_LYnRPGkOL7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5b: Computing the similarity between two English sentences at a specific layer (3 points)\n",
        "\n",
        "Note, you do NOT need to change `embed_sentence` or `sentence_similarity`. Changing them will cause you to lose points for this question."
      ],
      "metadata": {
        "id": "IDpOh_cUPutg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_sentence(model, tokenizer, s):\n",
        "  s_tokenized = tokenizer(s, return_tensors=\"pt\")\n",
        "  s_embeds = model(**s_tokenized, output_hidden_states=True)['hidden_states']\n",
        "  return s_embeds\n",
        "\n",
        "\n",
        "def embed_sentences(model, tokenizer, s1, s2):\n",
        "  s1_embeds = embed_sentence(model, tokenizer, s1)\n",
        "  s2_embeds = embed_sentence(model, tokenizer, s2)\n",
        "  return s1_embeds, s2_embeds\n",
        "\n",
        "\n",
        "def sentence_similarity(s1_embeds, s2_embeds, layer):\n",
        "  s1_vector = convert_embeds_to_vector(s1_embeds, layer)\n",
        "  s2_vector = convert_embeds_to_vector(s2_embeds, layer)\n",
        "  similarity = cosine_similarity(s1_vector, s2_vector).detach().item()\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "_dqq1GaDmPOw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ClFHk940K4_J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def convert_embeds_to_vector(embeds, layer):\n",
        "  # TODO: get sentence embeddings at a specific layer\n",
        "  sent_embeds = embeds[layer-1]\n",
        "  # TODO: compute the mean along axis=1 to turn the embeddings into a single vector of size (1, 768)\n",
        "  tensor = torch.tensor(sent_embeds,requires_grad=True)\n",
        "  convert_tensor_to_numpy = tensor.detach().numpy()\n",
        "  vector = np.mean(convert_tensor_to_numpy, axis=1)\n",
        "  # TODO: verify the shape of the vector is (1, 768) using assert\n",
        "  shape_vector = vector.shape\n",
        "  assert shape_vector[0] == 1\n",
        "  assert shape_vector[1] == 768\n",
        "\n",
        "  return torch.from_numpy(vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After editing the above code, run the cell below. The output you should get is that sentence 1 and sentence 2 have cosine similarity $\\approx 0.95$."
      ],
      "metadata": {
        "id": "G3SLt_puTb6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = 'My cat Vector is very cute.'\n",
        "sent2 = 'Professor Jacobs has a cat named Vector who is very cute.'\n",
        "\n",
        "s1_embeds, s2_embeds = embed_sentences(engbert, engtokenizer, sent1, sent2)\n",
        "print(sentence_similarity(s1_embeds, s2_embeds, layer=6))"
      ],
      "metadata": {
        "id": "-Eb7nsrXTekh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d76883b-f300-4a53-9395-b5c4238e67ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9495340585708618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5c: Computing the similarity between all English gold and translated sentences at all layers (3 points)\n",
        "\n",
        "Create a nested `for` loop to iterate through all the sentences in `english` using `sentence_similarity` from Q5b.\n",
        "\n",
        "Outer loop -- all sentences\n",
        "\n",
        "Inner loop -- all layers\n",
        "\n",
        "Print averages of all layers out at the end"
      ],
      "metadata": {
        "id": "iBbXnyGzQItf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "layer_sims = defaultdict(list)\n",
        "j = 0\n",
        "for outer in english:\n",
        "  data1= \"\".join((outer[-2].strip('\\n').split('\\n')))\n",
        "  data2 = \"\".join(outer[-1].strip('\\n').split('\\n'))\n",
        "  temp_list = []\n",
        "  for i in range(13):\n",
        "    s1_embeds, s2_embeds = embed_sentences(engbert, engtokenizer, data1, data2)\n",
        "    temp_list.append(sentence_similarity(s1_embeds, s2_embeds, layer= i))\n",
        "    if i == 12:\n",
        "      j = j + 1\n",
        "      layer_sims['layer ' + str(j-1)] = temp_list\n",
        "      break"
      ],
      "metadata": {
        "id": "YwrO4qgEVxu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da10754a-be13-40e5-f404-9bfa3c46a67e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(layer_sims)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSEPHvBZKC_V",
        "outputId": "c18e2d12-343c-4cdc-8df2-219cd06a130e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'list'>, {'layer 0': [0.9694236516952515, 0.9370449781417847, 0.9469146728515625, 0.9575198292732239, 0.95558762550354, 0.9661802649497986, 0.9723868370056152, 0.9776244163513184, 0.978664219379425, 0.9805426001548767, 0.9857415556907654, 0.9856081008911133, 0.9899044036865234], 'layer 1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 2': [0.9830528497695923, 0.9710646867752075, 0.9753118753433228, 0.9790318012237549, 0.9802778959274292, 0.9844610095024109, 0.9862881898880005, 0.9889016151428223, 0.9860441088676453, 0.9867919683456421, 0.9891160130500793, 0.9890556931495667, 0.992056667804718], 'layer 3': [0.8592914342880249, 0.7399447560310364, 0.7949160933494568, 0.8179962635040283, 0.8191359639167786, 0.8485340476036072, 0.8640307188034058, 0.880382776260376, 0.8818475604057312, 0.8888779282569885, 0.904603123664856, 0.9183129668235779, 0.9334012269973755], 'layer 4': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 5': [0.9497950077056885, 0.8791565299034119, 0.9091147780418396, 0.9282153844833374, 0.9278373122215271, 0.9410073757171631, 0.9509604573249817, 0.9538447260856628, 0.9478105902671814, 0.9520452618598938, 0.9619907736778259, 0.9713538289070129, 0.978108286857605], 'layer 6': [0.9457134008407593, 0.9711873531341553, 0.9725469946861267, 0.9783126711845398, 0.9782741665840149, 0.9813587665557861, 0.9836636185646057, 0.9844083189964294, 0.9814774990081787, 0.9757308959960938, 0.9700888991355896, 0.9709019064903259, 0.9744826555252075], 'layer 7': [0.9521181583404541, 0.8554150462150574, 0.915179431438446, 0.9404738545417786, 0.9425179362297058, 0.954063892364502, 0.9680569171905518, 0.9753080606460571, 0.9772065281867981, 0.9747889637947083, 0.9749021530151367, 0.9762070775032043, 0.9793195128440857], 'layer 8': [0.9769302606582642, 0.9439103603363037, 0.9427103400230408, 0.954737663269043, 0.952698290348053, 0.9631452560424805, 0.968867301940918, 0.9733431339263916, 0.9745432734489441, 0.9781678318977356, 0.9826552867889404, 0.9827452301979065, 0.9874417781829834], 'layer 9': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 10': [0.9628504514694214, 0.913064181804657, 0.951152503490448, 0.9628804922103882, 0.9599608182907104, 0.9664032459259033, 0.9699394106864929, 0.9710644483566284, 0.9679626822471619, 0.9633588194847107, 0.9704091548919678, 0.9748314023017883, 0.983661413192749], 'layer 11': [0.9906483292579651, 0.9838666319847107, 0.9844993948936462, 0.9874573349952698, 0.9870717525482178, 0.9903759360313416, 0.9924622774124146, 0.9921724200248718, 0.9924817085266113, 0.9921737313270569, 0.9941042065620422, 0.9941035509109497, 0.9960110187530518], 'layer 12': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 13': [0.994607150554657, 0.9890050888061523, 0.9894863367080688, 0.991176962852478, 0.9925249218940735, 0.9944424033164978, 0.995786190032959, 0.996176540851593, 0.9958317875862122, 0.9960585832595825, 0.9971945285797119, 0.9961848855018616, 0.9973530173301697], 'layer 14': [0.9868288040161133, 0.9853366017341614, 0.9923113584518433, 0.9930804371833801, 0.9904387593269348, 0.9899492263793945, 0.9908386468887329, 0.9904619455337524, 0.9878545999526978, 0.9859098196029663, 0.9886548519134521, 0.9891436100006104, 0.9930092096328735], 'layer 15': [0.9114193916320801, 0.9208001494407654, 0.9423090815544128, 0.9448022842407227, 0.9325849413871765, 0.9356774091720581, 0.9434253573417664, 0.9487472772598267, 0.9410157203674316, 0.9378793239593506, 0.9474648833274841, 0.951161801815033, 0.9595223069190979], 'layer 16': [0.7820949554443359, 0.6532331705093384, 0.7349449992179871, 0.7669467926025391, 0.7631065845489502, 0.8095616102218628, 0.8218395113945007, 0.8311513066291809, 0.8269385099411011, 0.838080644607544, 0.8715327382087708, 0.8889715671539307, 0.9177939295768738], 'layer 17': [0.9510474801063538, 0.8807871341705322, 0.9127097129821777, 0.9349724650382996, 0.9383430480957031, 0.95488041639328, 0.9620106816291809, 0.9620062112808228, 0.960165798664093, 0.9539722800254822, 0.962922215461731, 0.9694293737411499, 0.9783530235290527], 'layer 18': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 19': [0.9919031262397766, 0.9606444835662842, 0.970431923866272, 0.975109338760376, 0.9787726402282715, 0.9850830435752869, 0.9891510605812073, 0.9924216866493225, 0.9936052560806274, 0.9941883683204651, 0.9963621497154236, 0.9970606565475464, 0.9977710843086243], 'layer 20': [0.971251368522644, 0.8935695886611938, 0.9221006631851196, 0.9385174512863159, 0.9431882500648499, 0.9573157429695129, 0.9640671610832214, 0.9720458388328552, 0.9731144905090332, 0.9766805768013, 0.9838656783103943, 0.985816478729248, 0.9891301393508911], 'layer 21': [0.9821045398712158, 0.9129151105880737, 0.9484775066375732, 0.9627664685249329, 0.9610434770584106, 0.9677265286445618, 0.9787452220916748, 0.980974018573761, 0.9817003607749939, 0.9843770861625671, 0.9889912605285645, 0.990242063999176, 0.9932228922843933], 'layer 22': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 23': [0.957021951675415, 0.916766881942749, 0.9403780102729797, 0.9531670212745667, 0.958256721496582, 0.9669486284255981, 0.9702756404876709, 0.9602398872375488, 0.9604254364967346, 0.9609682559967041, 0.9674086570739746, 0.9694662094116211, 0.9750802516937256], 'layer 24': [0.9933953881263733, 0.9730859994888306, 0.9811935424804688, 0.9856780171394348, 0.9890115261077881, 0.992910623550415, 0.9942311644554138, 0.9952288269996643, 0.9952847957611084, 0.9952608942985535, 0.996508777141571, 0.9957057237625122, 0.9971612095832825], 'layer 25': [0.9902715682983398, 0.9646334052085876, 0.9818649888038635, 0.9855003952980042, 0.9865878820419312, 0.9914498329162598, 0.994918704032898, 0.9967772364616394, 0.9963808655738831, 0.9925664663314819, 0.9924319386482239, 0.992030143737793, 0.9940064549446106], 'layer 26': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 27': [0.9862430095672607, 0.9602668285369873, 0.9742134213447571, 0.9801036715507507, 0.9805839657783508, 0.987088680267334, 0.9875143766403198, 0.9882318377494812, 0.9882537126541138, 0.9888929724693298, 0.9906203746795654, 0.9917133450508118, 0.9941927790641785], 'layer 28': [0.9585742950439453, 0.8947628140449524, 0.9394702911376953, 0.94734787940979, 0.9430638551712036, 0.9546390771865845, 0.9624878168106079, 0.9603056311607361, 0.9562638401985168, 0.956443190574646, 0.9623978137969971, 0.9679643511772156, 0.9804410338401794], 'layer 29': [0.9662564396858215, 0.9319224953651428, 0.9574579000473022, 0.9694151282310486, 0.9717879891395569, 0.9790595769882202, 0.9834223985671997, 0.9856109023094177, 0.9807702302932739, 0.9781099557876587, 0.9803023338317871, 0.9818293452262878, 0.9885835647583008], 'layer 30': [0.902974545955658, 0.8488414883613586, 0.8937004804611206, 0.9063917398452759, 0.9088171720504761, 0.9293220043182373, 0.9370079636573792, 0.9441263675689697, 0.935502827167511, 0.9309922456741333, 0.9395058155059814, 0.9484760761260986, 0.963497519493103], 'layer 31': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 32': [0.9817903637886047, 0.9637019038200378, 0.9636508226394653, 0.9719523191452026, 0.9777439832687378, 0.9818198680877686, 0.9851915240287781, 0.9863783717155457, 0.984665036201477, 0.9862534403800964, 0.9896500110626221, 0.9887760281562805, 0.9915163516998291], 'layer 33': [0.9856659770011902, 0.972341001033783, 0.9813773036003113, 0.9854984879493713, 0.9875166416168213, 0.9897270798683167, 0.9915318489074707, 0.9921138882637024, 0.9908708930015564, 0.9902522563934326, 0.9915570020675659, 0.9909895062446594, 0.9935995936393738], 'layer 34': [0.9450479745864868, 0.861693263053894, 0.8929843306541443, 0.9145441055297852, 0.9188732504844666, 0.9438865780830383, 0.9522602558135986, 0.9612460732460022, 0.9637981653213501, 0.9664202332496643, 0.9670519828796387, 0.9676676392555237, 0.9735130667686462], 'layer 35': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 36': [0.9285520911216736, 0.9149030447006226, 0.9398812651634216, 0.9551934599876404, 0.9567570090293884, 0.9629107117652893, 0.9672387838363647, 0.9686734080314636, 0.9692143201828003, 0.9657585620880127, 0.962192714214325, 0.9577359557151794, 0.9657120108604431], 'layer 37': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 38': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 39': [0.9676294326782227, 0.9045307040214539, 0.9278435111045837, 0.9340867400169373, 0.941620409488678, 0.9574211835861206, 0.9657882452011108, 0.9719470739364624, 0.9729166626930237, 0.9726160764694214, 0.9800781011581421, 0.9842727184295654, 0.9877222776412964], 'layer 40': [0.9699670076370239, 0.9311493635177612, 0.9440447092056274, 0.9516792893409729, 0.9527794122695923, 0.9685646295547485, 0.9749369025230408, 0.9800990223884583, 0.9787550568580627, 0.9785815477371216, 0.9821116924285889, 0.9839486479759216, 0.9876024723052979], 'layer 41': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 42': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 43': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 44': [0.9486231803894043, 0.9563719034194946, 0.950011134147644, 0.9643958210945129, 0.9681729078292847, 0.9675295948982239, 0.973418116569519, 0.9779787659645081, 0.9789624214172363, 0.9782476425170898, 0.9829957485198975, 0.9807795882225037, 0.9833174347877502], 'layer 45': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 46': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'layer 47': [0.9929622411727905, 0.9891372919082642, 0.9938697814941406, 0.9934968948364258, 0.9924384355545044, 0.9920766353607178, 0.9922198057174683, 0.9924119710922241, 0.992601752281189, 0.9927080273628235, 0.9940319657325745, 0.9949066638946533, 0.9965919852256775], 'layer 48': [0.9347010850906372, 0.9048848748207092, 0.9408881068229675, 0.9535394310951233, 0.952670693397522, 0.9627118110656738, 0.9641685485839844, 0.9687923789024353, 0.9659373760223389, 0.9605976343154907, 0.9626035094261169, 0.9658642411231995, 0.9750298261642456], 'layer 49': [0.9889914393424988, 0.9465398192405701, 0.95048987865448, 0.9595434665679932, 0.9642311334609985, 0.9760900139808655, 0.9811447858810425, 0.9849003553390503, 0.9860223531723022, 0.9886122941970825, 0.9921329617500305, 0.9938728213310242, 0.9957355856895447]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over each layer in layer_sims and print the average\n",
        "dict1 = {}\n",
        "for key in layer_sims:\n",
        "  for i in range(0,13):\n",
        "    if i in dict1:\n",
        "      dict1[i].append(layer_sims[key][i])\n",
        "    else:\n",
        "      dict1[i] = [layer_sims[key][i]]\n",
        "\n",
        "average = []\n",
        "for key in dict1:\n",
        "  avg = np.mean(dict1[key])\n",
        "  print(avg)\n",
        "  average.append(avg)"
      ],
      "metadata": {
        "id": "5nQwZGnbI7BK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b566f1-a6c6-4994-8ef5-a3357aa73977"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9711949670314789\n",
            "0.9445295786857605\n",
            "0.9591687428951263\n",
            "0.9665106272697449\n",
            "0.9670855474472045\n",
            "0.9738864541053772\n",
            "0.9776055288314819\n",
            "0.9797219347953796\n",
            "0.9788978087902069\n",
            "0.9788581275939942\n",
            "0.9820836174488068\n",
            "0.9837425839900971\n",
            "0.9876769196987152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5d: Compute the similarity between all Finnish gold and translated sentences at all layers (3 points)\n",
        "\n",
        "Create a `for` loop to iterate through all the sentences in `finnish` using `sentence_similarity` from Q5b.\n",
        "\n",
        "Outer loop -- all sentences\n",
        "\n",
        "Inner loop -- all layers\n",
        "\n",
        "Print averages of all layers out at the end"
      ],
      "metadata": {
        "id": "gazIju2AQyEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sims = defaultdict(list)\n",
        "j = 0\n",
        "for outer in finnish:\n",
        "  data1= \"\".join((outer[-2].strip('\\n').split('\\n')))\n",
        "  data2 = \"\".join(outer[-1].strip('\\n').split('\\n'))\n",
        "  temp_list = []\n",
        "  for i in range(13):\n",
        "    s1_embeds, s2_embeds = embed_sentences(engbert, engtokenizer, data1, data2)\n",
        "    temp_list.append(sentence_similarity(s1_embeds, s2_embeds, layer= i))\n",
        "    if i == 12:\n",
        "      j = j + 1\n",
        "      layer_sims['layer ' + str(j-1)] = temp_list\n",
        "      break"
      ],
      "metadata": {
        "id": "BkROJveRV7II",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481648b0-5b50-4ee8-f7f3-143759faf269"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over each layer in layer_sims and print the average\n",
        "dict1 = {}\n",
        "for key in layer_sims:\n",
        "  for i in range(0,13):\n",
        "    if i in dict1:\n",
        "      dict1[i].append(layer_sims[key][i])\n",
        "    else:\n",
        "      dict1[i] = [layer_sims[key][i]]\n",
        "\n",
        "average = []\n",
        "for key in dict1:\n",
        "  avg = np.mean(dict1[key])\n",
        "  print(avg)\n",
        "  average.append(avg)"
      ],
      "metadata": {
        "id": "jxuqUH0dOfgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544c1fe5-d3b9-4ff9-da97-757dd1d5894e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9646093988418579\n",
            "0.921919367313385\n",
            "0.9406355464458466\n",
            "0.9456805217266083\n",
            "0.9490394127368927\n",
            "0.961135778427124\n",
            "0.9669098603725433\n",
            "0.9717363572120666\n",
            "0.9730573797225952\n",
            "0.9732820308208465\n",
            "0.9777024221420288\n",
            "0.9793009424209594\n",
            "0.9834346938133239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6: Compare and contrast exact matches to embedding distances (3 points)\n",
        "\n",
        "Exact matches and embedding distances can be thought of as two opposite ends of a spectrum. Write down 1 clear advantage that you see for each method over the other one (1 point each). For example, what information does an an embedding distance give you over an exact string match, and vice versa? Can you think of specific cases in the above analyses where neither method is very good? (1 point)"
      ],
      "metadata": {
        "id": "h66qx0pydxk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Because of the embedding distance, is we get to know that, how one sentence is similar to another sentence. It first finds out distance of each word to another word and it creates one matrix. From that matrix we can get an idea about exact string similar score.\n",
        "*   And if the two statements are same from begining, then the distance between them is zero. That means, if the distace is zero meaning two sentences are same and if it contains any value then it shows how similar the one sentence is to another.\n",
        "*   Whether the method is good or not is all based on size of the vector. If we have a huge amount of data then we can select other methods or distances to calculate similarity between them.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "znhQijZzd2qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus: Compute string similarity between gold and machine translated sentences (5 points)\n",
        "\n",
        "There are a number of ways two strings can be similar but different. Consider any **ONE** (1) of the following measures for computing the **mean** similarity between the gold sentence and the machine translated sentence. Summarize why that measure would be appropriate for comparing the input and output strings. Consider discussion of these points throughout the SLP3 book as well as Wikipedia as well as [Manning, Wein, and Schneider (2020)](https://aclanthology.org/2020.coling-main.420.pdf). You may use any off-the-shelf implementation that you find as long as you cite it below.\n",
        "\n",
        "* [BLEU](https://en.wikipedia.org/wiki/BLEU)\n",
        "* [ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric))\n",
        "* [Levenstein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance)\n",
        "\n",
        "For full points, this question must:\n",
        "\n",
        "1. Justify the metric (NO quoting from Wikipedia)\n",
        "2. Summarize the results for English AND Finnish\n",
        "3. Cite all sources"
      ],
      "metadata": {
        "id": "Td6WLaeNrqTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "id": "OXPab-4yYiA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein"
      ],
      "metadata": {
        "id": "ofOh5QTJYvO8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code for english"
      ],
      "metadata": {
        "id": "lpwaBNX27AfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus code here\n",
        "## Code for English\n",
        "similarity_score = []\n",
        "for outer in english:\n",
        "  data1= \"\".join((outer[-2].strip('\\n').split('\\n')))\n",
        "  data2 = \"\".join(outer[-1].strip('\\n').split('\\n'))\n",
        "  similarity = Levenshtein.distance(data1, data2)\n",
        "  similarity_score.append(similarity)"
      ],
      "metadata": {
        "id": "4UZQ24LsZHwh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhRnKjACLXpk",
        "outputId": "f6415d70-d8db-4048-f5f4-87f052eb114f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 0, 4, 8, 0, 12, 2, 4, 7, 0, 5, 4, 0, 7, 4, 3, 5, 7, 0, 7, 4, 2, 0, 8, 6, 2, 0, 4, 5, 37, 29, 0, 6, 14, 8, 0, 7, 0, 0, 4, 14, 0, 0, 0, 6, 0, 0, 3, 10, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code for finnish"
      ],
      "metadata": {
        "id": "q0ujsBVl7JDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Code for Finnish\n",
        "similarity_score = []\n",
        "for outer in finnish:\n",
        "  data1= \"\".join((outer[-2].strip('\\n').split('\\n')))\n",
        "  data2 = \"\".join(outer[-1].strip('\\n').split('\\n'))\n",
        "  similarity = Levenshtein.distance(data1, data2)\n",
        "  similarity_score.append(similarity)\n"
      ],
      "metadata": {
        "id": "I5PDPsLLNrSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t262yD6CQjgx",
        "outputId": "4f903f97-13db-4d8d-c393-5801f03a9781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 0, 7, 7, 0, 0, 16, 14, 8, 14, 0, 12, 0, 7, 7, 6, 10, 8, 0, 12, 16, 0, 9, 9, 0, 7, 7, 17, 11, 0, 6, 9, 0, 15, 11, 9, 0, 0, 2, 1, 5, 10, 20, 4, 9, 11, 0, 11, 0, 19]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What exactly is a Levenstein Distance?\n",
        "> Levenstein Distance is used to calculate the distance between two string sequences where the distance score will be after how many insertion, deletion and substitution the one string is similar to the another.\n",
        "> It uses dynamic programming approach, where the each words of the sentence is compared with the another one. And then we get the distace.\n",
        "*  In above code, the similarity score between two english sentence for the first sentence is 10 i.e after 10 insertion, deletion, and substitution the first sentence will be exactly be equal to second sentence. Similar with the two finnish sentences.\n",
        "* *Reference:*\n",
        "  *   https://www.cuelogic.com/blog/the-levenshtein-algorithm\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IEsooKjYM5C8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission format (1 point)\n",
        "\n",
        "Please upload the file with the name\n",
        "\n",
        "LASTNAME_FIRSTNAME_HW5.ipynb"
      ],
      "metadata": {
        "id": "ReECQdyfiJfK"
      }
    }
  ]
}