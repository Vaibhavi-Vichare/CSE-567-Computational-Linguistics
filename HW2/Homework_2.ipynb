{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccD5Kq24WAN3"
      },
      "source": [
        "# Question 1 (5 points)\n",
        "Load in all of the packages you will need for this assignment in the cell below. \n",
        "\n",
        "If you load in other packages later in the notebook, be sure to bring them up here. This is good coding practice and will look cleaner for everyone when reading your code.\n",
        "\n",
        "You will need the following:\n",
        "\n",
        "* To load a plain text file (`abstracts.tsv`) in with the colab interface (either local to your drive or by uploading the file to the notebook)\n",
        "* The NLTK tokenizer for English\n",
        "* The spaCy word tokenizer for English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfOQBQztFnqW"
      },
      "source": [
        "# Load in packages that you will use in this notebook\n",
        "from pprint import pprint\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "# put other packages you will use below this line\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZSPSo-TWTxL"
      },
      "source": [
        "# Question 2 (1 point)\n",
        "\n",
        "Load in the file called `abstracts.tsv` in the `data/` subdirectory of this folder into this notebook.\n",
        "\n",
        "Uncomment one of the two blocks below.\n",
        "\n",
        "Then, edit the line that you uncommented to load in abstracts.tsv.\n",
        "\n",
        "Note that using the `files` command requires you to do a bit more work to load the file in in Question 3. Be sure to check previous notebooks.\n",
        "\n",
        "If you do this in Jupyter on your own machine, please load in the file in the same manner without these imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl225PcgV61a"
      },
      "source": [
        "# Block 1: File stored on your google drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# if you go this route, then your code to open abstracts.txt goes here\n",
        "# \n",
        "\n",
        "# Block 2: File stored on your computer that you upload to the notebook directly\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRL5OkT4Wn-4"
      },
      "source": [
        "# Question 3: 3 points\n",
        "\n",
        "In this section, we will be comparing different preprocessing strategies. For this question, you should first preview the data by looking at the first 5 lines. Use [a slice](https://stackoverflow.com/questions/509211/understanding-slice-notation) to print the first five elements from the array.\n",
        "\n",
        "Then, separate all of the abstracts on all whitespace. Store this in an array of string arrays called `split_abstracts`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq6-78b1IGPm"
      },
      "source": [
        "# preview data (print the first five lines)\n",
        "\n",
        "# split every sentence on whitespace and save array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UqHOFeVIGzB"
      },
      "source": [
        "# Question 4: 4 points\n",
        "\n",
        "Now, we are going to use the `nltk` `word_tokenize` function. You should have loaded this above in the very first block. Use `word_tokenize` on all the abstracts and store this in an array of string arrays called `nltk_tokenized_abstracts`. Use a slice to print the fifth to the tenth elements of the array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8oOzoHiIzdh"
      },
      "source": [
        "# use nltk's word_tokenize function over all of the abstracts\n",
        "\n",
        "# save the output into a variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PpfhdWSI0Me"
      },
      "source": [
        "# Question 5: 5 points\n",
        "\n",
        "Now, we are going to use the `spacy` tokenization function. The output that spacy gives you is more complicated than the output of `nltk`'s `word_tokenize` function, because the `spacy` API takes a string (e.g., \"I like cheese\") and returns a `Doc` object. Within the `Doc` object there are `Token`s, and each `Token` has a `text` object. \n",
        "\n",
        "For this question, what you need to do is implement another loop through all of the abstracts, and store a list (array) of all of the token _strings_ from each `Token` object. If you were paying attention during the tokenization lecture this should be easy.\n",
        "\n",
        "Store all of these tokenizations into an array of string arrays called `spacy_tokenized_abstracts`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTwCwQ7nM8dX"
      },
      "source": [
        "# use spacy's tokenization features\n",
        "\n",
        "# save the output into a variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLC2daI-Myn1"
      },
      "source": [
        "# Question 6: Compare tokenizations (8 points)\n",
        "\n",
        "Now that we have three tokenizations (`split_abstracts`, `nltk_tokenized_abstracts`, and `spacy_tokenized_abstracts`), we want to compare how similar the tokenizations are. Pick a slice of 5 abstracts with any start and end indices. Demonstrate that the total number of abstracts that you selected is 5 by printing the length of that subset of abstracts.\n",
        "\n",
        "Tokenize each of the 5 abstracts according to each of the three approach above, and print their output in the code cell below. Then, in the cell below that, explain how these tokenizations differ. What are the strengths and weaknesses of each tokenization approach? Do you think one of the tokenizations is better than another? Can you think of a way you would test which one is better? Refer to justification from the readings where appropriate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sZ7km6oRYZs"
      },
      "source": [
        "### Question 6A: Code (3/8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld_dCKjLQaqf"
      },
      "source": [
        "# select a slice of 5 abstracts from the documents\n",
        "\n",
        "# print the length of this slice to show that it is five abstracts\n",
        "\n",
        "# Hint: Get the tokenizations from all 3 tokenization schemes by using the random indices in Hint 1\n",
        "\n",
        "# print the outputs of each of these 3 tokenizations for all 5 abstracts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CbwIX8AQm9Y"
      },
      "source": [
        "### Question 6B: Free response (5/8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCVSKvDZGUDS"
      },
      "source": [
        "$\\color{red}{\\text{Put your description of the above output here. Double click in this cell to edit it. Delete this line when you are done.}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlivQPJXf6m2"
      },
      "source": [
        "# Question 7: Tabulating word counts under different algorithms (8 points)\n",
        "\n",
        "Now that you have compared and contrasted different tokenization algorithms, consider the effect that tokenization can have on our ability to characterize a corpus as a whole. \n",
        "\n",
        "Load in the `Counter` module and extract counts of all of the words under each of the three tokenizations schemes. Look at the top 5 most frequent (using the `.most_frequent()` method) and the top 10 least frequent (hint: use negative indices) words. In our data, what appear to be the biggest sources of disagreement? Do these confirm or disconfirm your hypotheses in the previous question? How or how not? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjwPTSJA_txp"
      },
      "source": [
        "### Question 7A: Code (3/8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiXEsEaVdJTB"
      },
      "source": [
        "## Your code for question 6 goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bud1U9iM_vgh"
      },
      "source": [
        "### Question 7B: Free response (5/8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTWirBBEGPjO"
      },
      "source": [
        "$\\color{red}{\\text{Put your description of the above output here. Double click in this cell to edit it. Delete this line when you are done.}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FvuYyre5F_P"
      },
      "source": [
        "# Question 8: Tabulating pointwise mutual information under different tokenization schemes: 8 points\n",
        "\n",
        "Mutual information is a computation that is very similar to computing a conditional probability. Recall that computing a conditional probability, defined below, requires knowing two probabilities. The first, $p(A \\cap B)$, is the probability of observing $A$ and $B$ at the same time. The second, $p(A)$, is the probability of observing $A$ across all contexts.\n",
        "\n",
        "Recall that we can approximate all of these by their frequencies in a corpus. For example, $p(A)$ can be approximated by:\n",
        "\n",
        "<center> $\\large p(A) \\approx \\frac{count(A)}{\\sum_{w \\in V}count(w)}$ </center>\n",
        "\n",
        "A conditional probability like $p(B | A)$ is a measure that allows us to estimate how many of our observations of $B$ occur having already seen $A$.\n",
        "\n",
        "<center>$\\large p(B | A) = \\frac{p(A \\cap B)}{p(A)}$</center>\n",
        "\n",
        "Mutual information is very similar, but requires dividing the co-occurence statistic by two probabilities $p(A)$ and $p(B)$.\n",
        "\n",
        "<center>$\\large MI = \\frac{p(A \\cap B)}{p(A) \\cdot p(B)}$</center>\n",
        "\n",
        "<hr />\n",
        "\n",
        "This question contains multiple parts to respond to.\n",
        "\n",
        "1. Compute the bigram frequencies of all words in our `abstracts.tsv` corpus. You may use whatever tokenization scheme you think performs the best.\n",
        "2. Pick one of your tokenized abstracts from Question 5 that you think sounds interesting.\n",
        "3. For each of the bigrams in that abstracts, compute the mutual information of that bigram and print the bigram and its mutual information value to the notebook.\n",
        "4. Answer the questions in the free response section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pXgmepfDDAm"
      },
      "source": [
        "### Question 8A: Computing mutual information for bigrams in one sentence (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXPXWtAfCRGy"
      },
      "source": [
        "## your code for question 7 goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIEw6FcsdZ1f"
      },
      "source": [
        "### Question 8B: Free response (3 points)\n",
        "\n",
        "Characterize the different mutual information values of the sentence you used. What values are highest? What values are lowest? When do you think mutual information would be a better statistic to compute than a conditional probability?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzshSnbtGMCo"
      },
      "source": [
        "### <font color='red'>Your written response for question 8B goes here</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCgDQrOaICRl"
      },
      "source": [
        "# Submission guidelines (1 point)\n",
        "\n",
        "Please upload your completed notebook file to UBLearns in the following format:\n",
        "\n",
        "Lastname\\_Firstname\\_HW2.ipynb\n",
        "\n",
        "e.g., Smith\\_John\\_HW2.ipynb."
      ]
    }
  ]
}